[sandbox_workspace_write]
network_access = true

[notice]
"hide_gpt-5.1-codex-max_migration_prompt" = true

[profiles.gpt-5-1-codex]
model = "gpt-5.1-codex"
model_provider = "azure"
model_reasoning_effort = "high"
wire_api = "responses"

[profiles.mistral-large-3]
model = "Mistral-Large-3"
model_provider = "azure"
model_reasoning_effort = "high"

[profiles.deepseek-v3-0324]
model = "DeepSeek-V3-0324"
model_provider = "azure"
model_reasoning_effort = "high"

[profiles.gpt-5-1]
model = "gpt-5.1"
model_provider = "azure"
model_reasoning_effort = "high"
wire_api = "responses"

[profiles.gpt-oss-120b]
model = "gpt-oss-120b"
model_provider = "azure"
model_reasoning_effort = "high"
wire_api = "responses"

[model_providers.azure]
name = "Azure OpenAI"
base_url = ADD_AZURE_URL_HERE # AZURE URL GOES HERE
env_key = "AZURE_OPENAI_API_KEY"
stream_idle_timeout_ms = 259200000

# Send CLI telemetry to the mini-otel sink run_evals.py starts locally.
[otel]
environment = "staging"
log_user_prompt = false
exporter = { otlp-grpc = { endpoint = "http://127.0.0.1:4317" } }
